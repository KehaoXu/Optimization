{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "\n",
    "n=train.shape[1]-2 #number of features\n",
    "x_train=train.iloc[:,:n]\n",
    "y1_train=train.iloc[:,n:n+1] #family\n",
    "y2_train=train.iloc[:,n+1:n+2] #species\n",
    "\n",
    "x_test=test.iloc[:,:n] \n",
    "y1_test=test.iloc[:,n:n+1] #family\n",
    "y2_test=test.iloc[:,n+1:n+2] #species\n",
    "\n",
    "print(n)\n",
    "# print(train.head())\n",
    "# print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(y):\n",
    "    x=pd.Series()\n",
    "\n",
    "    id=y.columns[0]\n",
    "    idx=y.value_counts().index\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        x[i]=x_train[y[id].str.contains(idx[i][0],case=False,na=False)] #split the data into different classes\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapp(y_train,y_test):\n",
    "    \n",
    "    f=y_train.value_counts() #family\n",
    "    # print(f)\n",
    "    # f.index[0][0]\n",
    "    mapping = {\n",
    "        f.index[i][0]: i for i in range(len(f))\n",
    "    }\n",
    "\n",
    "    return y_test.replace(mapping) #mapping y_test to 0,1,2,3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(i,x1:pd.DataFrame,j,x2:pd.DataFrame,x_test:pd.DataFrame,g:np.array,r:float) -> int|np.ndarray:\n",
    "    x=pd.concat([x1,x2]) #combine two classes\n",
    "    y=pd.DataFrame(np.zeros((x1.shape[0]+x2.shape[0],1)))\n",
    "    y.iloc[:x1.shape[0]]=1 #label for class 1\n",
    "    y.iloc[x1.shape[0]:]=-1 #label for class 2\n",
    "\n",
    "    x=x.values #convert to np\n",
    "    y=y.values\n",
    "    x_test=x_test.values\n",
    "\n",
    "    a=cp.Variable((n,1))\n",
    "    b=cp.Variable()\n",
    "    eta=cp.Variable((x.shape[0],1))\n",
    "    gamma=cp.Parameter(nonneg=True)\n",
    "\n",
    "    obj=cp.Minimize(cp.norm(a,2)+gamma*cp.norm(eta,1)/x.shape[0])\n",
    "    const=[cp.multiply(y,cp.matmul(x,a)-b)>=1-eta,eta>=0]\n",
    "\n",
    "    prob=cp.Problem(obj,const)\n",
    "\n",
    "    train_error=np.zeros(len(g))\n",
    "    pred=np.zeros((len(g),len(x_test))) #prediction for test data\n",
    "\n",
    "    # A=np.zeros((len(g),n,1))\n",
    "    # B=np.zeros(len(g))\n",
    "    # test_error=np.zeros(len(g))\n",
    "\n",
    "    for t in range(len(g)):\n",
    "        gamma.value=g[t]\n",
    "\n",
    "        prob.solve()\n",
    "        \n",
    "        a1=a.value #pd to np\n",
    "        b1=b.value\n",
    "        eta1=eta.value\n",
    "\n",
    "        # if (i==0 and j==2 and t==2):\n",
    "        #     # print(a1.T)\n",
    "        #     print(b1)\n",
    "\n",
    "        a1[np.abs(a1)<=r]=0 #remove small values\n",
    "        # print(np.sum(a1==0))\n",
    "\n",
    "        # print(i,j,t)\n",
    "        # if (i==0 and j==2 and t==2):\n",
    "        #     print(a1.T)\n",
    "        #     print(b1)\n",
    "\n",
    "        train_error[t]=np.mean(eta1>1e-3) #error rate\n",
    "        \n",
    "        pred[t]=np.array([i if ((x_test@a1)[k]-b1)>0 else j for k in range(len(x_test))]) #prediction for test data\n",
    "    \n",
    "    train_error1=train_error[train_error>0] #remove gamma with error rate less than 0.01\n",
    "    pred1=pred[train_error>0]\n",
    "\n",
    "    if train_error1.size==0: #if all gamma have error rate less than 0.01\n",
    "        min_train_error=1 \n",
    "        min_pred=pred[0]\n",
    "    else:    \n",
    "        min_train_error=np.min(train_error1) #minimum train error over gamma\n",
    "        min_pred=pred1[np.argmin(train_error1)] #prediction for test data with minimum train error\n",
    "\n",
    "    return min_train_error,min_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.ones((5,10))\n",
    "b=np.ones((10,1))\n",
    "np.dot(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel_matrix(X_new, X_sv, sigma, alpha, y):\n",
    "\n",
    "    X_new_sq = np.sum(X_new**2, axis=1).reshape(-1, 1)  # Shape: (n_samples, 1)\n",
    "    X_sv_sq = np.sum(X_sv**2, axis=1).reshape(1, -1)   # Shape: (1, n_sv)\n",
    "    dist = X_new_sq + X_sv_sq - 2 * np.dot(X_new, X_sv.T)  # Shape: (n_samples, n_sv)\n",
    "    K=np.exp(-dist/(2*sigma**2))\n",
    "\n",
    "    a=np.sum(np.dot(K, alpha * y),axis=1)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_kernel(i,x1:pd.DataFrame,j,x2:pd.DataFrame,x_test:pd.DataFrame,r:float,sigma:float,C:float) -> int|np.ndarray:\n",
    "    x=pd.concat([x1,x2]) #combine two classes\n",
    "    y=pd.DataFrame(np.zeros((x1.shape[0]+x2.shape[0],1)))\n",
    "    y.iloc[:x1.shape[0]]=1 #label for class 1\n",
    "    y.iloc[x1.shape[0]:]=-1 #label for class 2\n",
    "\n",
    "    x=x.values #convert to np\n",
    "    y=y.values\n",
    "    x_test=x_test.values\n",
    "\n",
    "    n=x.shape[0] #number of data points\n",
    "\n",
    "    x_square = np.sum(x**2, axis=1, keepdims=True)\n",
    "    dist = x_square + x_square.T - 2 * x@x.T\n",
    "    K = np.exp(-0.5 * dist/(sigma**2))\n",
    "\n",
    "    Y = np.diag(y.reshape(-1)) #diagonal matrix of y\n",
    "    Q = Y@K@Y\n",
    "\n",
    "    alpha = cp.Variable(n)\n",
    "    c = cp.Parameter(nonneg=True)\n",
    "    \n",
    "    obj = cp.Minimize(0.5 * cp.quad_form(alpha, Q) - cp.sum(alpha)) #dual obj\n",
    "    const = [alpha>=0, alpha <= c, y.T@alpha == 0] \n",
    "    prob = cp.Problem(obj, const)\n",
    "\n",
    "    min_train_error=1\n",
    "    y_pred=np.zeros(len(x_test))\n",
    "\n",
    "    for c.value in C:       \n",
    "        prob.solve()\n",
    "        alpha1 = alpha.value\n",
    "\n",
    "        # alpha1[np.abs(alpha1)<r]=0 #remove small values\n",
    "\n",
    "        ## Compute b\n",
    "        idx = np.where((alpha1 >= 1e-6) & (alpha1 <= c.value), True, False)\n",
    "        if len(idx) == 0:\n",
    "            raise ValueError \n",
    "        \n",
    "        b = np.mean(y[idx]-rbf_kernel_matrix(x[idx], x, sigma, alpha1, y))\n",
    "\n",
    "        ## Compute train error\n",
    "        y_pred_train = np.sign(rbf_kernel_matrix(x, x, sigma, alpha1, y)+ b)\n",
    "        train_error = np.mean(y_pred_train != y) #train error\n",
    "\n",
    "        if min_train_error>train_error: #update minimum train error\n",
    "            min_train_error=train_error\n",
    "\n",
    "            ## Compute test prediction\n",
    "            f_x = rbf_kernel_matrix(x_test, x, sigma, alpha1, y) + b # Shape: (n_x_test, 1)\n",
    "            # print(f_x.shape)\n",
    "            y_pred=np.array([i if f_x[k]>0 else j for k in range(len(x_test))]) #prediction for test data\n",
    "\n",
    "    return min_train_error,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logis(i,x1:pd.DataFrame,j,x2:pd.DataFrame,x_test:pd.DataFrame,r:float)-> int|np.ndarray:\n",
    "    x=pd.concat([x1,x2]) #combine two classes\n",
    "    y=pd.DataFrame(np.zeros((x1.shape[0]+x2.shape[0],1)))\n",
    "    y.iloc[:x1.shape[0]]=1 #label for class 1\n",
    "    y.iloc[x1.shape[0]:]=-1 #label for class 2\n",
    "\n",
    "    x=x.values #convert to np\n",
    "    y=y.values\n",
    "    x_test=x_test.values\n",
    "\n",
    "    w=cp.Variable((n,1))\n",
    "    b=cp.Variable()\n",
    "\n",
    "    obj=cp.Minimize(cp.sum(cp.logistic(-cp.multiply(y,x@w-b)))/x.shape[0])\n",
    "    const=[]\n",
    "\n",
    "    prob=cp.Problem(obj,const)\n",
    "    \n",
    "    prob.solve()\n",
    "\n",
    "    w1=w.value #pd to np\n",
    "    b1=b.value\n",
    "\n",
    "    w1[np.abs(w1)<=r]=0 #remove small values\n",
    "    # print((w1==0).T) #number of zero values\n",
    "\n",
    "    train_error=np.mean(y!=np.sign(x@w1-b1)) #error rate\n",
    "    # print(train_error)\n",
    "\n",
    "    pred=np.array([i if (x_test@w1-b1)[k]>0 else j for k in range(len(x_test))]) #prediction for test data\n",
    "\n",
    "    return train_error,pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver(i,x1:pd.DataFrame,j,x2:pd.DataFrame,x_test:pd.DataFrame,g:np.ndarray,r:float,sigma:float,C:np.ndarray,T:str):\n",
    "    if T=='svm':\n",
    "        return svm(i,x1,j,x2,x_test,g,r)\n",
    "    elif T=='logistic':\n",
    "        return logis(i,x1,j,x2,x_test,r)\n",
    "    elif T=='svm+kernel':\n",
    "        return svm_kernel(i,x1,j,x2,x_test,r,sigma,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1=classify(y1_train) #split the data into different families\n",
    "x_train_2=classify(y2_train) #split the data into different species\n",
    "# print(x_train_1[0].shape)\n",
    "# print(x_train_2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86136\\AppData\\Local\\Temp\\ipykernel_17776\\2238513263.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return y_test.replace(mapping) #mapping y_test to 0,1,2,3\n",
      "C:\\Users\\86136\\AppData\\Local\\Temp\\ipykernel_17776\\2238513263.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return y_test.replace(mapping) #mapping y_test to 0,1,2,3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y1_test=mapp(y1_train,y1_test) #mapping family to 0,1,2,3\n",
    "y2_test=mapp(y2_train,y2_test) #mapping species to 0,1,2,3\n",
    "# print(y2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true,y_pred):\n",
    "    n=len(np.unique(y_true))\n",
    "    cm=np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cm[i,j]=np.sum((y_true==i)&(y_pred==j))\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_one(x_train:pd.DataFrame,x_test:pd.DataFrame,y_test:pd.DataFrame,g:np.array,R:np.array,sigma:float,C:np.ndarray,T:str):\n",
    "\n",
    "    m=len(x_train) #number of classes\n",
    "    nm=(m*(m-1)//2) #number of models\n",
    "\n",
    "    train_error=np.ones(nm)\n",
    "    pred=np.zeros((nm,len(x_test))) #predict raw result for test data\n",
    "    result=np.zeros((len(y_test),1)) #predict result for test data\n",
    "    # test_error=np.zeros(len(g)) \n",
    "\n",
    "    t=0 #index for train_error and pred\n",
    "    for i in range(m): \n",
    "        for j in range(i+1,m): #solve C(m,2) models\n",
    "            for r in R:\n",
    "                temp=solver(i,x_train[i],j,x_train[j],x_test,g,r,sigma,C,T)\n",
    "                # print(i,j,r,temp[0])\n",
    "                if train_error[t]>temp[0]:\n",
    "                    train_error[t],pred[t]=temp #minimize train error over r\n",
    "            t=t+1\n",
    "\n",
    "    #analyze pred           \n",
    "    for idx,col in enumerate(pred.T):\n",
    "        counts=np.bincount(col.astype(int)) #count the number of each class\n",
    "        result[idx]=np.argmax(counts) #choose the class with the most counts as the prediction\n",
    "\n",
    "    test_error=np.sum(result!=y_test.values)/len(y_test) #error rate for test data\n",
    "    mean_train_error=np.mean(train_error)\n",
    "\n",
    "    print(\"test_error:\",test_error)\n",
    "    print(\"mean_train_error:\",mean_train_error)\n",
    "    print(\"confusion matrix:\\n\",confusion_matrix(y_test.values,result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_rest(x_train:pd.DataFrame,x_test:pd.DataFrame,y_test:pd.DataFrame,g:np.array,R:np.array,sigma:float,C:np.ndarray,T:str):\n",
    "\n",
    "    m=len(x_train) #number of classes\n",
    "    \n",
    "    train_error=np.ones(m)\n",
    "    pred=np.zeros((m,len(x_test)))  #predict raw result for test data\n",
    "    result=np.zeros((len(y1_test),1)) #predict result for test data\n",
    "    # test_error=np.zeros(len(g)) \n",
    "\n",
    "    for i in range(m): #solve m models\n",
    "        x_train_rest=pd.concat([x_train[j] for j in range(m) if j!=i]) #combine all other classes\n",
    "        for r in R:\n",
    "            temp=solver(i,x_train[i],-1,x_train_rest,x_test,g,r,sigma,C,T)\n",
    "            if train_error[i]>temp[0]:\n",
    "                train_error[i],pred[i]=temp #minimize train error over r\n",
    "\n",
    "    #analyze pred\n",
    "    for idx,col in enumerate(pred.T):\n",
    "        if (np.sum(col != -1)==1): #classification unambiguous\n",
    "            result[idx]=np.max(col)\n",
    "        else: #classification ambiguous\n",
    "            result[idx]=-1 \n",
    "\n",
    "    test_error=np.sum(result!=y1_test.values)/len(y1_test) #error rate for test data\n",
    "    mean_train_error=np.mean(train_error)\n",
    "            \n",
    "    print(\"test_error:\",test_error)\n",
    "    print(\"mean_train_error:\",mean_train_error)\n",
    "    print(\"confusion matrix:\\n\",confusion_matrix(y_test.values,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(task,Type,class_tech,r):\n",
    "    '''\n",
    "    task='family' or 'species',\\n\n",
    "    Type='svm' or 'logistic' or 'svm+kernel',\\n\n",
    "    class_tech='one_vs_rest' or 'one_vs_one',\\n\n",
    "    r=post-processing parameter,\n",
    "    '''\n",
    "    if task=='family':\n",
    "        x_train=x_train_1\n",
    "        y_test=y1_test\n",
    "    elif task=='species':\n",
    "        x_train=x_train_2\n",
    "        y_test=y2_test\n",
    "\n",
    "    if class_tech=='one_vs_one':\n",
    "        g=np.array([0.1,1,5,10,50,1e2,1e3,1e4,1e5]) #gamma for SVM\n",
    "        sigma=1 #sigma for RBF kernel\n",
    "        C=np.array([1e-3,1e-2,1e-1,1,1e1,1e2,1e3,1e5,1e7])\n",
    "\n",
    "        one_vs_one(x_train,x_test,y_test,g,r,sigma,C,Type)\n",
    "\n",
    "    elif class_tech=='one_vs_rest':\n",
    "        g=np.array([1e-2,0.1,1,5,10,50,1e2,1e3,1e4,1e5]) #gamma for SVM\n",
    "        sigma=1 #sigma for RBF kernel\n",
    "        C=np.array([1e-3,1e-2,1e-1,1,1e1,1e2,1e3,1e5,1e7])\n",
    "\n",
    "        one_vs_rest(x_train,x_test,y_test,g,r,sigma,C,Type)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.04983388704318937\n",
      "mean_train_error: 0.03775584232918908\n",
      "confusion matrix:\n",
      " [[174.   0.   1.   0.]\n",
      " [  7.  85.   1.   3.]\n",
      " [  1.   1.  25.   0.]\n",
      " [  1.   0.   0.   2.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r=np.exp(np.linspace(-3,1,20))\n",
    "model('family','svm','one_vs_one',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.06312292358803986\n",
      "mean_train_error: 0.03847990192023274\n",
      "confusion matrix:\n",
      " [[136.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  46.   1.   0.   0.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.  27.   0.   1.   0.   1.   0.   0.   0.]\n",
      " [  0.   1.   1.  21.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   1.   0.   0.  25.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   1.   9.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  10.   0.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.   6.   2.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   1.   0.   2.   0.]\n",
      " [  0.   4.   0.   2.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "r=np.exp(np.linspace(-3,1,20))\n",
    "model('species','svm','one_vs_one',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.09966777408637874\n",
      "mean_train_error: 0.07832618025751073\n",
      "confusion matrix: [[169.   1.   1.   0.]\n",
      " [  5.  83.   2.   0.]\n",
      " [  2.   1.  19.   0.]\n",
      " [  1.   2.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r=np.exp(np.linspace(-3,1,20))\n",
    "model('family','svm','one_vs_rest',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.4053156146179402\n",
      "mean_train_error: 0.018597997138769667\n",
      "confusion matrix: [[135.   0.   0.   0.   0.   0.   0.   1.   0.   0.]\n",
      " [  0.  44.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  24.   0.   1.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.  17.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  19.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   7.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   9.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   1.   0.   4.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   1.   0.   0.   0.]\n",
      " [  0.   0.   0.   1.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "### ???\n",
    "r=np.exp(np.linspace(-4,1,20))\n",
    "model('species','svm','one_vs_rest',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Downloadssoftware\\Anaconda3\\envs\\py3-optimize\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.04983388704318937\n",
      "mean_train_error: 0.007303077725612937\n",
      "confusion matrix:\n",
      " [[174.   0.   1.   0.]\n",
      " [  7.  85.   1.   3.]\n",
      " [  1.   1.  25.   0.]\n",
      " [  1.   0.   0.   2.]]\n"
     ]
    }
   ],
   "source": [
    "r=np.exp(np.linspace(-3,1,20))\n",
    "# r=np.linspace(1.6,1.7,20)\n",
    "model('family','logistic','one_vs_one',r) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.046511627906976744\n",
      "mean_train_error: 0.0\n",
      "confusion matrix:\n",
      " [[136.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  1.  47.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   1.  26.   0.   2.   0.   0.   0.   0.   0.]\n",
      " [  0.   2.   0.  20.   0.   0.   0.   0.   0.   1.]\n",
      " [  0.   0.   0.   0.  26.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   1.   9.   0.   0.   0.   0.]\n",
      " [  0.   1.   0.   0.   0.   0.   9.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   9.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.   0.   2.   0.]\n",
      " [  0.   0.   0.   3.   0.   0.   0.   0.   0.   3.]]\n"
     ]
    }
   ],
   "source": [
    "r=np.exp(np.linspace(-4,3,20))\n",
    "# r=np.linspace(1.6,1.7,20)\n",
    "model('species','logistic','one_vs_one',r) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.132890365448505\n",
      "mean_train_error: 0.030042918454935626\n",
      "confusion matrix: [[167.   1.   2.   1.]\n",
      " [  6.  75.   1.   0.]\n",
      " [  1.   0.  18.   0.]\n",
      " [  1.   0.   0.   1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r=np.exp(np.linspace(-3,1,20))\n",
    "model('family','logistic','one_vs_rest',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.43521594684385384\n",
      "mean_train_error: 0.006008583690987125\n",
      "confusion matrix: [[134.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  36.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  21.   0.   2.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.  14.   0.   0.   0.   0.   1.   0.]\n",
      " [  0.   0.   0.   0.  24.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   9.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   9.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   1.   0.   5.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   2.   0.]\n",
      " [  0.   0.   0.   1.   0.   0.   0.   0.   0.   1.]]\n"
     ]
    }
   ],
   "source": [
    "r=np.exp(np.linspace(-3,1,20))\n",
    "model('species','logistic','one_vs_rest',r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.2558139534883721\n",
      "mean_train_error: 0.1486828865641258\n",
      "confusion matrix:\n",
      " [[175.   0.   0.   0.]\n",
      " [ 47.  49.   0.   0.]\n",
      " [ 26.   1.   0.   0.]\n",
      " [  1.   2.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "r=np.exp(np.linspace(-3,1,20))\n",
    "model('family','svm+kernel','one_vs_one',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.31893687707641194\n",
      "mean_train_error: 0.255844995431067\n",
      "confusion matrix:\n",
      " [[133.   0.   3.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  43.   5.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  29.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  23.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  27.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  1.   0.   9.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  10.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   9.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   1.   2.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   6.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "model('species','svm+kernel','one_vs_one',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.2757475083056478\n",
      "mean_train_error: 0.22765047554139267\n",
      "confusion matrix: [[175.   0.   0.   0.]\n",
      " [ 37.  43.   0.   0.]\n",
      " [ 26.   0.   0.   0.]\n",
      " [  1.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "model('family','svm+kernel','one_vs_rest',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 0.5946843853820598\n",
      "mean_train_error: 0.11937224852179999\n",
      "confusion matrix: [[77.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 44.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 15.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "model('species','svm+kernel','one_vs_rest',r) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some problems on the logistic model with species data and the kernel SVM model. The test error is so high and there are maybe some overfitting. I will continue to debug it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3  \n",
    "Theoretically, kernel SVM and one-vs-one should perform the best. Because it extracts more features from original datasets and creates more precise models.  \n",
    "It is more difficult to predict species, because species has more categories than family."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4  \n",
    "The logistic model is the least computationally intensive and the kernel SVM model is the most.  \n",
    "The one-vs-rest technique is the least computationally intensive and the one-vs-one is the most.  \n",
    "The more the computation is, the higher the testing accuracy is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5  \n",
    "I have not tested it. But I set the parameter r to remove small values of the parameter(such as a and w etc.) in the models. If the value is removed, the feature is least important.  \n",
    "The easier the model is and the fewer categories the datasets have , the easier I might interpret it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6  \n",
    "We need to minimize x times error_rate + y times spending time.  \n",
    "Since I have not got correct error rates on some of the above models, I can not get the lowest cost model. But based on the current result, I would like to to choose logistic model with one-vs-one technique for small scale classification problem (only few categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-optimize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
